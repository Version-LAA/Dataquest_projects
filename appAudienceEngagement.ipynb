{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application Audience Engagement\n",
    "\n",
    "The purpose and goal of this app is to analyze two data sets on apps in both the Google Playstore, and the Apple App Store to identify which type of apps are likely to attract more users. The criteria used in this analysis include only free apps, apps in the english language. \n",
    "\n",
    "Source of Google Data: https://www.kaggle.com/lava18/google-play-store-apps\n",
    "- [ rows] and 13 columns\n",
    "\n",
    "Source of Apple Data: https://www.kaggle.com/ramamet4/app-store-apple-data-set-10k-apps\n",
    "- 7,197 rows and 16 columns\n",
    "\n",
    "Note:\n",
    "\n",
    "This was a guided project a part of Dataquest project: Profitable App Profiles for the App Store and Google Play Market\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Data Exploration\n",
      "\n",
      "['id', 'track_name', 'size_bytes', 'currency', 'price', 'rating_count_tot', 'rating_count_ver', 'user_rating', 'user_rating_ver', 'ver', 'cont_rating', 'prime_genre', 'sup_devices.num', 'ipadSc_urls.num', 'lang.num', 'vpp_lic']\n",
      "\n",
      "\n",
      "['284882215', 'Facebook', '389879808', 'USD', '0.0', '2974676', '212', '3.5', '3.5', '95.0', '4+', 'Social Networking', '37', '1', '29', '1']\n",
      "\n",
      "\n",
      "Number of rows: 7198\n",
      "Number of columns: 16\n",
      "\n",
      "\n",
      "Google Data Exploration\n",
      "\n",
      "['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver']\n",
      "\n",
      "\n",
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "Number of rows: 10842\n",
      "Number of columns: 13\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "\n",
    "#Open and read the apple store dataset and convert into a list.\n",
    "open_apple = open('AppleStore.csv')\n",
    "read_apple =reader(open_apple)\n",
    "apple_dataset = list(read_apple)\n",
    "\n",
    "#Open and read the google playstore dtaset and convert into a list\n",
    "open_google = open('googleplaystore.csv')\n",
    "read_google= reader(open_google)\n",
    "google_dataset = list(read_google)\n",
    "\n",
    "\n",
    "\n",
    "def explore_data(dataset, start, end, rows_and_columns=False):\n",
    "    dataset_slice = dataset[start:end]    \n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print('\\n') # adds a new (empty) line after each row\n",
    "\n",
    "    if rows_and_columns:\n",
    "        print('Number of rows:', len(dataset))\n",
    "        print('Number of columns:', len(dataset[0]))\n",
    "\n",
    "\n",
    "print('Apple Data Exploration\\n')\n",
    "explore_data (apple_dataset,0,2,True)\n",
    "print(\"\\n\")\n",
    "\n",
    "print('Google Data Exploration\\n')\n",
    "explore_data (google_dataset,0,2,True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration\n",
    "\n",
    "Using and calling the explore_data() function, provided me with context and information on the datasets such as the column headers, number of rows, and number of columns. This data will help identify which columns can be used to accomplish our goal of identifing the apps in both app stores that are the most popular. \n",
    "\n",
    "explore_data (apple_dataset,0,2,True)\n",
    "explore_data (google_dataset,0,2,True)\n",
    "\n",
    "1. Apple Data\n",
    "- Number of rows: 7198 and Number of columns: 16\n",
    "- Columns: ['id', 'track_name', 'size_bytes', 'currency', 'price', 'rating_count_tot', 'rating_count_ver', 'user_rating', 'user_rating_ver', 'ver', 'cont_rating', 'prime_genre', 'sup_devices.num', 'ipadSc_urls.num', 'lang.num', 'vpp_lic']\n",
    "\n",
    "2. Google Data\n",
    "- Number of rows: 10842; Number of columns: 13\n",
    "- ['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver']\n",
    "\n",
    "### Data Cleaning pt 1.\n",
    "\n",
    "- Upon reading the the discussion form for the google app dataset, there was a post that discussed an error in column 10473 that was missing a filed. I performed a deletion of the row with the missing data. There was no errors identified in the discussion form for apple data.\n",
    "\n",
    "- There were a number of duplicate apps identified within the google dataset for apps (i.e. instagram). It was identified that the reviews column can be used to identify data that was collected at different times. Therefore, I will not remove duplicates randomly, but will retain the row for that specific app with the most reviews. This can indicate the most recent update for that app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google - with up to 5 examples\n",
      "Duplicates: 1181 \n",
      " ['Quick PDF Scanner + OCR FREE', 'Box', 'Google My Business', 'ZOOM Cloud Meetings', 'join.me - Simple Meetings']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#This will delete the fow that is missing data. This was ran once, and can not be ran again w/o deleting correct data.\n",
    "\n",
    "del google_dataset[10472]\n",
    "\n",
    "'''Created a function called duplicate_finder which is used to identify the number \n",
    "duplicate apps within the dataset. Will return number of duplicates found for specific index and print duplicates.\n",
    "\n",
    "'''\n",
    "\n",
    "def duplicate_finder(dataset,column_index):\n",
    "    duplicate_field = []\n",
    "    unique_field= []\n",
    "    \n",
    "    for element in dataset:\n",
    "        name = element[column_index]\n",
    "        if name in unique_field:\n",
    "            duplicate_field.append(name)\n",
    "        else:\n",
    "            unique_field.append(name)\n",
    "    return print('Duplicates:', len(duplicate_field),'\\n',duplicate_field[:5])\n",
    "   \n",
    "\n",
    "#calls function duplicate finder on the google dataset for apps with duplicate names.    \n",
    "\n",
    "print('Google - with up to 5 examples')\n",
    "duplicate_finder(google_dataset,0)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9659\n"
     ]
    }
   ],
   "source": [
    "'''The following loops through the google dataset, identifies the app and it's corresponding\n",
    "max number of reviews and adds the name and max review amount to a new dictionary.\n",
    "\n",
    "'''\n",
    "reviews_max = {}\n",
    "\n",
    "\n",
    "for app in google_dataset[1:]:\n",
    "    name = app[0]\n",
    "    n_reviews = app[3]\n",
    "    \n",
    "    if name in reviews_max and reviews_max[name] < n_reviews:\n",
    "        reviews_max[name] = n_reviews\n",
    "    elif name not in reviews_max:\n",
    "        reviews_max[name] = n_reviews\n",
    "\n",
    "\n",
    "print(len(reviews_max))\n",
    "\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning pt. 2\n",
    "\n",
    "1. Using the new dictionary we created above with the duplicate apps that had the max reviews. I created two empty list, one to store clean data, and the other to keep track of the app as we add them to the clean list.\n",
    "\n",
    "2. After looping through the dataset, if the number of reviews is equal to the max number of reviews for that app, and the app does not exist in the already_added list, we will append the entire row into the android_clean list. The already_added list is there to keep track of apps already added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9659\n"
     ]
    }
   ],
   "source": [
    "android_clean =[]\n",
    "already_added = []\n",
    "count = 0\n",
    "\n",
    "for app in google_dataset[1:]:\n",
    "    name = app[0]\n",
    "    n_reviews = app[3]\n",
    "    count +=1\n",
    "    if n_reviews == reviews_max[name] and (name not in already_added):\n",
    "        android_clean.append(app)\n",
    "        already_added.append(name)\n",
    "    \n",
    "  \n",
    "\n",
    "print(len(android_clean))\n",
    "\n",
    "#explore_data\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning pt. 3\n",
    "\n",
    "- Next step in cleaning the data will be filtering out non- english apps. I approached this by creating a function to help identify if a character is a non english using the char() function. Majority of english characters will return a char value between 0 - 127. But because some apps have/use emoji's , I created a function that allowed no more than 3 consecutive characters out of range to ensure we do not miss a lot of apps.\n",
    "\n",
    "- Final data cleaning effort will be to filter out free apps. So I created two new final list that appended only apps that were free.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 9614\n",
      "Number of columns: 13\n",
      "Number of rows: 7198\n",
      "Number of columns: 16\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def eng_char(string):\n",
    "    count = 0\n",
    "    for char in string:\n",
    "        if ord(char) > 127 :\n",
    "            count += 1\n",
    "            \n",
    "    if count > 3:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "filtered_google =[]\n",
    "filtered_apple = []\n",
    "\n",
    "for app in android_clean:\n",
    "    name = app[0]\n",
    "    if eng_char(name)is True:\n",
    "        filtered_google.append(app)\n",
    "    \n",
    "for app in apple_dataset:\n",
    "    name = app[2]\n",
    "    if eng_char(name)is True:\n",
    "        filtered_apple.append(app)\n",
    "        \n",
    "# explored new filtered list of english apps.\n",
    "        \n",
    "explore_data(filtered_google,0,0,True)\n",
    "\n",
    "explore_data(filtered_apple,0,0,True)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "apple 4056\n",
      "google  8859\n"
     ]
    }
   ],
   "source": [
    "#isolate free apps from filtered data\n",
    "\n",
    "final_apple =[]\n",
    "final_google=[]\n",
    "\n",
    "print(type(filtered_apple[1][4]))\n",
    "\n",
    "#apple\n",
    "\n",
    "for app in filtered_apple[1:]:\n",
    "    price = float(app[4])\n",
    "    \n",
    "    if price == 0:\n",
    "        final_apple.append(app)\n",
    "        \n",
    "for app in filtered_google[1:]:\n",
    "    price = app[6]\n",
    "    \n",
    "    if price == 'Free':\n",
    "        final_google.append(app)\n",
    "\n",
    "print('apple', len(final_apple))\n",
    "print('google ',len(final_google))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Pt1: Most Common Apps by Genre:\n",
    "\n",
    "Now that I have cleaned the data, below I Identified some fields from each dataset that may be helpful in accomplishing my goal of idenifying the most popular apps for both app stors. Will create frequency tables using some of these columns.\n",
    "\n",
    "Apple data key fields to use\n",
    "- track_name\n",
    "- ratingcountot\n",
    "- primary genre\n",
    "- user_rating\n",
    "\n",
    "google dta key fields to use\n",
    "- app\n",
    "- category\n",
    "- genre\n",
    "- rating\n",
    "- reviews\n",
    "- installs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google - Genre\n",
      "\n",
      "Everyone : 81.42921652743283\n",
      "Teen : 11.06344547301874\n",
      "Mature 17+ : 4.188304357642809\n",
      "Everyone 10+ : 3.2625874915330777\n",
      "Adults only 18+ : 0.03386769022352676\n",
      "Unrated : 0.022578460149017838\n",
      "\n",
      "\n",
      "Google - Category\n",
      "\n",
      "FAMILY : 18.932038834951456\n",
      "GAME : 9.69744863400316\n",
      "TOOLS : 8.45563332580718\n",
      "BUSINESS : 4.59471664032513\n",
      "LIFESTYLE : 3.9060736057800858\n",
      "PRODUCTIVITY : 3.894784375705577\n",
      "FINANCE : 3.7028674644389254\n",
      "MEDICAL : 3.5222397832467824\n",
      "SPORTS : 3.3980582524271843\n",
      "PERSONALIZATION : 3.307744411831113\n",
      "COMMUNICATION : 3.24000903138406\n",
      "HEALTH_AND_FITNESS : 3.0819598103409347\n",
      "PHOTOGRAPHY : 2.9464890494468277\n",
      "NEWS_AND_MAGAZINES : 2.7997290584782117\n",
      "SOCIAL : 2.6642582975841047\n",
      "TRAVEL_AND_LOCAL : 2.3368706254233462\n",
      "SHOPPING : 2.246556784827275\n",
      "BOOKS_AND_REFERENCE : 2.144953714156695\n",
      "DATING : 1.8627229622939716\n",
      "VIDEO_PLAYERS : 1.794987581846918\n",
      "MAPS_AND_NAVIGATION : 1.3998645292391059\n",
      "FOOD_AND_DRINK : 1.241815308195981\n",
      "EDUCATION : 1.1740799277489276\n",
      "ENTERTAINMENT : 0.9595845563332581\n",
      "LIBRARIES_AND_DEMO : 0.9370060961842402\n",
      "AUTO_AND_VEHICLES : 0.9257168661097314\n",
      "HOUSE_AND_HOME : 0.8241137954391511\n",
      "WEATHER : 0.8015353352901332\n",
      "EVENTS : 0.7112214946940618\n",
      "PARENTING : 0.6547753443215173\n",
      "COMICS : 0.6209076540979905\n",
      "ART_AND_DESIGN : 0.6209076540979905\n",
      "BEAUTY : 0.5983291939489727\n",
      "\n",
      "\n",
      "Apple - Category\n",
      "\n",
      "Games : 55.659679408138096\n",
      "Entertainment : 8.236744759556105\n",
      "Photo & Video : 4.1183723797780525\n",
      "Social Networking : 3.501849568434032\n",
      "Education : 3.255240443896424\n",
      "Shopping : 2.9839704069050557\n",
      "Utilities : 2.688039457459926\n",
      "Lifestyle : 2.318125770653514\n",
      "Finance : 2.0715166461159065\n",
      "Sports : 1.9482120838471024\n",
      "Health & Fitness : 1.8742293464858202\n",
      "Music : 1.6522811344019728\n",
      "Book : 1.627620221948212\n",
      "Productivity : 1.528976572133169\n",
      "News : 1.4303329223181258\n",
      "Travel : 1.381011097410604\n",
      "Food & Drink : 1.060419235511714\n",
      "Weather : 0.7644882860665845\n",
      "Reference : 0.4932182490752158\n",
      "Navigation : 0.4932182490752158\n",
      "Business : 0.4932182490752158\n",
      "Catalogs : 0.22194821208384713\n",
      "Medical : 0.19728729963008632\n"
     ]
    }
   ],
   "source": [
    "#This function will help put tables in order.\n",
    "\n",
    "def display_table(dataset, index):\n",
    "    table = freq_table(dataset, index)\n",
    "    table_display = []\n",
    "    for key in table:\n",
    "        key_val_as_tuple = (table[key], key)\n",
    "        table_display.append(key_val_as_tuple)\n",
    "\n",
    "    table_sorted = sorted(table_display, reverse = True)\n",
    "    for entry in table_sorted:\n",
    "        print(entry[1], ':', entry[0])\n",
    "        \n",
    "#This function will create a frequency table based on a dataset, and column of choice. It will then return the table in percentages.\n",
    "\n",
    "def freq_table(dataset,index):\n",
    "    f_table = {}\n",
    "    f_table_percentage = {}\n",
    "    f_table_proportions={}\n",
    "    total = 0\n",
    "    \n",
    "   \n",
    "    for item in dataset[1:]:\n",
    "        value = item[index]\n",
    "        if value in f_table:\n",
    "            f_table[value] +=1\n",
    "        else:\n",
    "            f_table[value]=1\n",
    "    \n",
    "    for item in f_table:\n",
    "        f_table_proportions[item] = f_table[item] / len(dataset[1:])\n",
    "        f_table_percentage[item] = f_table_proportions[item] * 100\n",
    "\n",
    "    \n",
    "    \n",
    "    return f_table_percentage\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Google frequency table by Genre \n",
    "print('Google - Genre\\n')\n",
    "\n",
    "freq_table(final_google,8)\n",
    "\n",
    "display_table(final_google,8)\n",
    "\n",
    "\n",
    "#Google frequency table by Category \n",
    "print('\\n')\n",
    "\n",
    "print('Google - Category\\n')\n",
    "\n",
    "freq_table(final_google,1)\n",
    "\n",
    "display_table(final_google,1)\n",
    "\n",
    "\n",
    "#Apple frequency table by Category\n",
    "print('\\n')\n",
    "\n",
    "print('Apple - Category\\n')\n",
    "\n",
    "freq_table(final_apple,11)\n",
    "\n",
    "display_table(final_apple,11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Photo & Video': 27249.892215568863, 'Games': 18924.68896765618, 'Music': 56482.02985074627, 'Social Networking': 53078.195804195806, 'Reference': 67447.9, 'Health & Fitness': 19952.315789473683, 'Weather': 47220.93548387097, 'Utilities': 14010.100917431193, 'Travel': 20216.01785714286, 'Shopping': 18746.677685950413, 'News': 15892.724137931034, 'Navigation': 25972.05, 'Lifestyle': 8978.308510638299, 'Entertainment': 10822.961077844311, 'Food & Drink': 20179.093023255813, 'Sports': 20128.974683544304, 'Book': 8498.333333333334, 'Finance': 13522.261904761905, 'Education': 6266.333333333333, 'Productivity': 19053.887096774193, 'Business': 6367.8, 'Catalogs': 1779.5555555555557, 'Medical': 459.75}\n"
     ]
    }
   ],
   "source": [
    "'''This section will find out which genre are the most popular, and calculate the avg number of installs \n",
    "for each app genre for the apple app store\n",
    "'''\n",
    "\n",
    "table = freq_table(final_apple,11)\n",
    "\n",
    "rec_app = {}\n",
    "\n",
    "for element in table:\n",
    "    total = 0\n",
    "    len_genre = 0\n",
    "    for item in final_apple:\n",
    "        genre_app = item[11]\n",
    "        \n",
    "        if genre_app == element:\n",
    "            sum_user = float(item[5])\n",
    "            total +=sum_user\n",
    "            len_genre +=1\n",
    "    \n",
    "    rec_app[element]= total/len_genre\n",
    "\n",
    "print(rec_app)\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ART_AND_DESIGN  avg:  1967474.5454545454\n",
      "AUTO_AND_VEHICLES  avg:  647317.8170731707\n",
      "BEAUTY  avg:  513151.88679245283\n",
      "BOOKS_AND_REFERENCE  avg:  8767811.894736841\n",
      "BUSINESS  avg:  1712290.1474201474\n",
      "COMICS  avg:  817657.2727272727\n",
      "COMMUNICATION  avg:  38456119.167247385\n",
      "DATING  avg:  854028.8303030303\n",
      "EDUCATION  avg:  1820673.076923077\n",
      "ENTERTAINMENT  avg:  11640705.88235294\n",
      "EVENTS  avg:  253542.22222222222\n",
      "FINANCE  avg:  1387692.475609756\n",
      "FOOD_AND_DRINK  avg:  1924897.7363636363\n",
      "HEALTH_AND_FITNESS  avg:  4188821.9853479853\n",
      "HOUSE_AND_HOME  avg:  1331540.5616438356\n",
      "LIBRARIES_AND_DEMO  avg:  638503.734939759\n",
      "LIFESTYLE  avg:  1437816.2687861272\n",
      "GAME  avg:  15560965.599534342\n",
      "FAMILY  avg:  3696479.242695289\n",
      "MEDICAL  avg:  120616.48717948717\n",
      "SOCIAL  avg:  23253652.127118643\n",
      "SHOPPING  avg:  7036877.311557789\n",
      "PHOTOGRAPHY  avg:  17805627.643678162\n",
      "SPORTS  avg:  3638640.1428571427\n",
      "TRAVEL_AND_LOCAL  avg:  13984077.710144928\n",
      "TOOLS  avg:  10682301.033377837\n",
      "PERSONALIZATION  avg:  5218893.815699658\n",
      "PRODUCTIVITY  avg:  16787331.344927534\n",
      "PARENTING  avg:  542603.6206896552\n",
      "WEATHER  avg:  5074486.197183099\n",
      "VIDEO_PLAYERS  avg:  24727872.452830188\n",
      "NEWS_AND_MAGAZINES  avg:  9549178.467741935\n",
      "MAPS_AND_NAVIGATION  avg:  4056941.7741935486\n"
     ]
    }
   ],
   "source": [
    "'''This section will find out which genre are the most popular, and calculate the avg number of installs \n",
    "for each app genre for the google app store\n",
    "'''\n",
    "\n",
    "unique_google = freq_table(final_google,1)\n",
    "\n",
    "for element in unique_google:\n",
    "    category = element\n",
    "    total = 0\n",
    "    len_category = 0\n",
    "    \n",
    "    for item in final_google[1:]:\n",
    "        category_name = item[1]\n",
    "        \n",
    "        \n",
    "        if category_name == category:\n",
    "            num_installs = item[5]\n",
    "            num_installs = num_installs.replace('+','')\n",
    "            num_installs = num_installs.replace(',','')\n",
    "            \n",
    "            total += float(num_installs)\n",
    "            len_category +=1\n",
    "    avg = total/len_category\n",
    "    print(category,'','avg: ', avg)\n",
    "        \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
